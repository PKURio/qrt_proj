{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6597c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast,GradScaler\n",
    "import time\n",
    "import pickle\n",
    "from sam import SAM\n",
    "from dataset import PanelDataset\n",
    "from model import SelfAttnModel,GinAttnModel,EMA,Stage2Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1d9240",
   "metadata": {},
   "source": [
    "## get necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34df6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df_stage1=pd.read_csv(\"./qube/data/ashares_daily_stage1.csv\")\n",
    "    df_stage1_lite=df_stage1[[\"norm_wma_open\",\"norm_wma_close\",\"norm_wma_high\",\"norm_wma_low\",\"diff_log_vol\",\n",
    "                             \"f1\",\"f2\",\"f3\",\"trade_date\",\"return\",\"stock_id\"]]\n",
    "    np_stage1_lite=np.array(df_stage1_lite)\n",
    "    dict_colname_lite={}\n",
    "    for i,colname in enumerate(df_stage1_lite.columns.values.tolist()):\n",
    "        dict_colname_lite[colname]=i\n",
    "\n",
    "    dict_trade_date={}\n",
    "    for i,v in enumerate(np.sort(df_stage1_lite[\"trade_date\"].unique()).tolist()):\n",
    "        dict_trade_date[v]=i\n",
    "    \n",
    "    return np_stage1_lite,dict_colname_lite,dict_trade_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925094b",
   "metadata": {},
   "source": [
    "## loss & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7de6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_mse_loss(x,y):\n",
    "    x=x.squeeze()\n",
    "    y=y.squeeze()\n",
    "    valid=(y!=-1)\n",
    "    x=x[valid]\n",
    "    y=y[valid]\n",
    "    return nn.MSELoss()(x,y)\n",
    "\n",
    "def mask_pcc_loss(x,y):\n",
    "    x=x.squeeze()\n",
    "    y=y.squeeze()\n",
    "    valid=(y!=-1)\n",
    "    x=x[valid]\n",
    "    y=y[valid]\n",
    "    x_hat=th.mean(x)\n",
    "    y_hat=th.mean(y)\n",
    "    return 1-th.mean((x-x_hat)*(y-y_hat))/(th.std(x)*th.std(y))\n",
    "\n",
    "def mask_ccc_loss(x,y,only_long=False):\n",
    "    x=x.squeeze()\n",
    "    y=y.squeeze()\n",
    "    valid=(y>0) if only_long else (y!=-1)\n",
    "    x=x[valid]\n",
    "    y=y[valid]\n",
    "    x_hat=th.mean(x)\n",
    "    y_hat=th.mean(y)\n",
    "    return 1-2*th.mean((x-x_hat)*(y-y_hat))/(th.std(x)**2+th.std(y)**2+(x_hat-y_hat)**2)\n",
    "\n",
    "def get_position(x,y):\n",
    "    valid=(x>0)&(y!=-1)\n",
    "    x[~valid]=0\n",
    "    pos=x/th.sum(x,dim=1).view(-1,1)\n",
    "    return pos\n",
    "    \n",
    "def mask_sharpe_loss(x,y,evaluation=False):\n",
    "    \"\"\"\n",
    "    x num_day*1605\n",
    "    y num_day*1605\n",
    "    \"\"\"\n",
    "    rf=0.237\n",
    "    tf=0.0005\n",
    "    num_td=252\n",
    "    pos=get_position(x,y)\n",
    "    r=th.sum(pos*y,dim=1) # (num_day,)\n",
    "    sr=(num_td*th.mean(r)-rf)*0.5/(th.std(r,unbiased=False)*np.sqrt(num_td))\n",
    "    if evaluation:\n",
    "        r-=2*tf\n",
    "        nsr=(num_td*th.mean(r)-rf)*0.5/(th.std(r,unbiased=False)*np.sqrt(num_td))\n",
    "        return sr,nsr\n",
    "    else:\n",
    "        return -sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3876c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model,stage1_model,optimizer,loss_func,src,label,seq_len,scaler,use_sam=False):\n",
    "    model.train()\n",
    "    src=src.view(-1,seq_len,src.shape[-1])\n",
    "    src=stage1_model(src,stock_id=None,extra_output=True)[1].detach()\n",
    "    src=src.view(-1,1605,src.shape[-1])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        output=model(src)\n",
    "        output=output.view(-1,1605)\n",
    "        loss=loss_func(output,label)\n",
    "        \n",
    "    if use_sam:\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        loss_func(model(src).view(-1,1605),label).backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "    else:\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    return loss\n",
    "\n",
    "%%time\n",
    "def max_sr_optimization(pred,past_return):\n",
    "    def f(x,pred,cov):\n",
    "        std=np.sqrt(np.matmul(np.matmul(x,cov),x.T))\n",
    "        mean=np.matmul(pred,x.T)\n",
    "        func=-(mean/std)\n",
    "        return func\n",
    "\n",
    "    def constraint(x):\n",
    "        A=np.ones(x.shape)\n",
    "        b=1\n",
    "        return np.matmul(A,x.T)-b \n",
    "\n",
    "    pred=pred.detach().cpu().numpy()\n",
    "    past_return=past_return.detach().cpu().numpy().T\n",
    "\n",
    "    position=np.zeros(pred.shape[0])\n",
    "    valid=(pred>max(np.quantile(pred,0.5),0))\n",
    "    pred=pred[valid]\n",
    "    past_return=past_return[valid]\n",
    "    past_return[past_return==-1]=0\n",
    "    cov=np.cov(past_return)\n",
    "    \n",
    "    #define bounds and other parameters\n",
    "    xinit=np.repeat(1/pred.shape[0],pred.shape[0])\n",
    "    cons=({\"type\":\"eq\",\"fun\":constraint})\n",
    "    lb=0\n",
    "    ub=1\n",
    "    bnds=tuple([(lb,ub) for x in xinit])\n",
    "\n",
    "    #invoke minimize solver\n",
    "    opt=optimize.minimize(f,x0=xinit,args=(pred,cov),method=\"SLSQP\",bounds=bnds,constraints=cons,tol=10**-3)\n",
    "    position[valid]=opt['x']\n",
    "    return th.tensor(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f973258c",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213716bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(analytic=False):\n",
    "    np_stage1_lite,dict_colname_lite,dict_trade_date=get_data()\n",
    "    \n",
    "    GPU_VIS=0\n",
    "    th.manual_seed(0)\n",
    "    th.cuda.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    th.cuda.set_device(GPU_VIS)\n",
    "\n",
    "    seq_len=5\n",
    "    train_bs,test_bs,inc_bs=100,1,100\n",
    "    train_ranges=(20100000,20200000)\n",
    "    test_ranges=(20200000,20210000)\n",
    "    inc_start_day=[k for k,v in dict_trade_date.items() if v==dict_trade_date[20191231]-inc_bs+1][0]\n",
    "    inc_ranges=(inc_start_day,20200000)\n",
    "\n",
    "    train_set=PanelDataset(seq_len,np_stage1_lite,train_ranges,dict_colname_lite,dict_trade_date)\n",
    "    test_set=PanelDataset(seq_len,np_stage1_lite,test_ranges,dict_colname_lite,dict_trade_date)\n",
    "    inc_set=PanelDataset(seq_len,np_stage1_lite,inc_ranges,dict_colname_lite,dict_trade_date)\n",
    "\n",
    "    train_dataset=DataLoader(train_set,batch_size=train_bs,num_workers=4,pin_memory=False,shuffle=True)\n",
    "    test_dataset=DataLoader(test_set,batch_size=test_bs,num_workers=4,pin_memory=False,shuffle=False)\n",
    "    inc_dataset=DataLoader(inc_set,batch_size=inc_bs,num_workers=0,pin_memory=False,shuffle=False)\n",
    "\n",
    "    EPOCH=10\n",
    "    LR=1e-3\n",
    "    DECAY=0.999\n",
    "\n",
    "    args={\n",
    "        \"dropout\":[0.1],\n",
    "        \"in_dim\":32,\n",
    "    }\n",
    "\n",
    "    model=Stage2Model(**args).to(device=\"cuda\")\n",
    "    print(model)\n",
    "\n",
    "    ema=EMA(model,DECAY)\n",
    "    ema.register()\n",
    "\n",
    "    stage1_model_path=\"./qube/model/selfattn_st1_seq5_ic0.067_extra32\"\n",
    "    with open(f\"{stage1_model_path}.pkl\",\"rb\") as f:\n",
    "        stage1_model_args=pickle.load(f)\n",
    "\n",
    "    stage1_model=SelfAttnModel(**stage1_model_args).to(device=\"cuda\")\n",
    "    stage1_model.load_state_dict(th.load(f\"{stage1_model_path}.pt\",map_location=\"cuda\"))\n",
    "    stage1_model.eval()\n",
    "\n",
    "    optimizer=th.optim.AdamW(model.parameters(),lr=LR,weight_decay=1e-3)\n",
    "    # base_optimizer=th.optim.AdamW\n",
    "    # optimizer=SAM(model.parameters(),base_optimizer,lr=LR,rho=0.1,weight_decay=1e-3)\n",
    "\n",
    "    def loss_func(x,y):\n",
    "        return mask_mse_loss(x,y)+mask_ccc_loss(x,y)+0.01*mask_sharpe_loss(x,y)\n",
    "\n",
    "    scaler=GradScaler()\n",
    "    for epoch in range(EPOCH):\n",
    "        t1=time.time()\n",
    "        model.train()\n",
    "        total_loss=0\n",
    "        for idx,(src,label) in enumerate(train_dataset):\n",
    "            \"\"\"\n",
    "            src N*1605*seq_len*M\n",
    "            label N*1605\n",
    "            \"\"\"\n",
    "            src=src.cuda(non_blocking=True)\n",
    "            label=label.cuda(non_blocking=True)\n",
    "            loss=forward(model,stage1_model,optimizer,loss_func,src,label,seq_len,scaler,use_sam=False)\n",
    "            ema.update() \n",
    "            total_loss+=loss.item()\n",
    "\n",
    "        t2=time.time()\n",
    "        print(f\"[TRAIN] epoch {epoch+1} total loss {format(total_loss,'.4f')} elapsed time {int(t2-t1)}s\")\n",
    "        ema.apply_shadow()\n",
    "\n",
    "        th.save({\n",
    "            \"model_state_dict\":model.state_dict(),\n",
    "            \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "        },f\"./qube/tmp/gpuvis{GPU_VIS}.pt\")\n",
    "        ckpt=th.load(f\"./qube/tmp/gpuvis{GPU_VIS}.pt\")\n",
    "\n",
    "        inc_model=Stage2Model(**args).to(device=\"cuda\")\n",
    "        inc_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        inc_optimizer=th.optim.AdamW(inc_model.parameters(),lr=LR,weight_decay=1e-3)\n",
    "    #     inc_optimizer=SAM(inc_model.parameters(),base_optimizer,lr=LR,rho=0.1,weight_decay=1e-3)\n",
    "    #     inc_optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "        inc_ema=EMA(inc_model,DECAY,ema.get_shadow())\n",
    "\n",
    "        inc_src,inc_label=next(iter(inc_dataset))\n",
    "        inc_src=inc_src.to(device=\"cuda\")\n",
    "        inc_label=inc_label.to(device=\"cuda\")\n",
    "\n",
    "        all_pred=th.zeros(242,1605).cuda()\n",
    "        all_label=th.zeros(242,1605).cuda()\n",
    "        for idx,(src,label) in enumerate(test_dataset):\n",
    "            inc_model.eval()\n",
    "            inc_ema.apply_shadow()\n",
    "            with th.no_grad():\n",
    "                src=src.cuda(non_blocking=True)\n",
    "                label=label.cuda(non_blocking=True)\n",
    "                inc_src=th.concat((inc_src[1:],src),dim=0)\n",
    "\n",
    "                src=src.view(-1,seq_len,src.shape[-1])\n",
    "                src=stage1_model(src,stock_id=None,extra_output=True)[1].detach()\n",
    "                src=src.view(-1,1605,src.shape[-1])\n",
    "                \n",
    "                pred=inc_model(src)\n",
    "                pred=pred.flatten()\n",
    "                if analytic:\n",
    "                    pred=max_sr_optimization(pred,inc_label).to(\"cuda\")\n",
    "                    \n",
    "                all_pred[idx]=pred\n",
    "                all_label[idx]=label\n",
    "                inc_label=th.concat((inc_label[1:],label),dim=0)\n",
    "\n",
    "            inc_ema.restore()\n",
    "            forward(inc_model,stage1_model,inc_optimizer,loss_func,inc_src,inc_label,seq_len,scaler,use_sam=False)\n",
    "            inc_ema.update()\n",
    "\n",
    "        ic_test=1-mask_pcc_loss(all_pred,all_label).item()\n",
    "        sr_test,nsr_test=mask_sharpe_loss(all_pred,all_label,evaluation=True)\n",
    "        sr_test,nsr_test=sr_test.item(),nsr_test.item()\n",
    "\n",
    "        t3=time.time()\n",
    "        print(f\"[TEST] epoch {epoch+1} ic {format(ic_test,'.5f')} sr {format(sr_test,'.5f')} nsr {format(nsr_test,'.5f')} elapsed time {int(t3-t2)}s\")\n",
    "        print(f\"{'-'*100}\")\n",
    "        ema.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412fff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
